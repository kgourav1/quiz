[
  {
    "question": "Using a larger block size in a fixed block size file system leads to (GATE CS 2003)",
    "choice1": "better disk throughput but poorer disk space utilization",
    "choice2": "better disk throughput and better disk space utilization",
    "choice3": "poorer disk throughput but better disk space utilization",
    "choice4": "poorer disk throughput and poorer disk space utilization",
    "answer": 1,
    "explanation": "Correct answer is (a). Larger block size improves disk throughput due to reduced seek time, but it can lead to poorer disk space utilization because of internal fragmentation."
  },
  {
    "question": "Consider the following statements with respect to user-level threads and kernel-supported threads i. context switch is faster with kernel-supported threads ii. for user-level threads, a system call can block the entire process iii. Kernel supported threads can be scheduled independently iv. User level threads are transparent to the kernel Which of the above statements are true? (GATE CS 2004)",
    "choice1": "(ii), (iii) and (iv) only",
    "choice2": "(ii) and (iii) only",
    "choice3": "(i) and (iii) only",
    "choice4": "(i) and (ii) only",
    "answer": 1,
    "explanation": "Correct answer is (a). User-level threads suffer from the problem of blocking the entire process on a system call, while kernel-supported threads can be scheduled independently."
  },
  {
    "question": "The minimum number of page frames that must be allocated to a running process in a virtual memory environment is determined by (GATE CS 2004)",
    "choice1": "the instruction set architecture",
    "choice2": "page size",
    "choice3": "physical memory size",
    "choice4": "number of processes in memory",
    "answer": 1,
    "explanation": "Correct answer is (a). The minimum number of page frames required by a process depends on the instruction set architecture. For example, certain instructions may require multiple pages to execute."
  },
  {
    "question": "In a system with 32 bit virtual addresses and 1 KB page size, use of one-level page tables for virtual to physical address translation is not practical because of (GATE CS 2003)",
    "choice1": "the large amount of internal fragmentation",
    "choice2": "the large amount of external fragmentation",
    "choice3": "the large memory overhead in maintaining page tables",
    "choice4": "the large computation overhead in the translation process",
    "answer": 3,
    "explanation": "Correct answer is (c). One-level page tables in such a system would require a large amount of memory to store, leading to significant memory overhead."
  },

  {
    "question": "A process executes the code\n\nfork ();\nfork ();\nfork ();\nThe total number of child processes created is",
    "choice1": "3",
    "choice2": "4",
    "choice3": "7",
    "choice4": "8",
    "answer": 3,
    "explanation": "Correct answer is (C). Each call to fork() doubles the number of processes. So, with 3 fork() calls, the total number of child processes created is 2^3 - 1 = 7."
  },
  {
    "question": "Consider the 3 processes, P1, P2, and P3 shown in the table\n\nProcess Arrival time Time unit required\nP1 0 5\nP2 1 7\nP3 3 4\nThe completion order of the 3 processes under the policies FCFS and RRS (round robin scheduling with CPU quantum of 2 time units) are",
    "choice1": "FCFS: P1, P2, P3 RR2: P1, P2, P3",
    "choice2": "FCFS: P1, P3, P2 RR2: P1, P3, P2",
    "choice3": "FCFS: P1, P2, P3 RR2: P1, P3, P2",
    "choice4": "FCFS: P1, P3, P2 RR2: P1, P2, P3",
    "answer": 3,
    "explanation": "Correct answer is (C). Under FCFS, the processes complete in the order they arrive. Under RR2, each process gets 2 time units before the next process gets CPU time. Therefore, P1 and P3 complete first under RR2."
  },
  {
    "question": "Consider the virtual page reference string\n1, 2, 3, 2, 4, 1, 3, 2, 4, 1\nOn a demand-paged virtual memory system running on a computer system with main memory size of 3 page frames which are initially empty. Let LRU, FIFO, and OPTIMAL denote the number of page faults under the corresponding page replacements policy. Then",
    "choice1": "OPTIMAL < LRU < FIFO",
    "choice2": "OPTIMAL < FIFO < LRU",
    "choice3": "OPTIMAL = LRU",
    "choice4": "OPTIMAL = FIFO",
    "answer": 2,
    "explanation": "Correct answer is (B). OPTIMAL has the fewest page faults, followed by FIFO and then LRU. This is because OPTIMAL has perfect knowledge of future page accesses."
  },
  {
    "question": "A file system with 300 GByte uses a file descriptor with 8 direct block address, 1 indirect block address, and 1 doubly indirect block address. The size of each disk block is 128 Bytes and the size of each disk block address is 8 Bytes. The maximum possible file size in this file system is",
    "choice1": "3 Kbytes",
    "choice2": "35 Kbytes",
    "choice3": "280 Bytes",
    "choice4": "Dependent on the size of the disk",
    "answer": 2,
    "explanation": "Correct answer is (B). By calculating the maximum number of addressable bytes due to each block address, we can determine the maximum file size supported by this file system."
  },
  {
    "question": "A thread is usually defined as a ‘lightweight process’ because an operating system (OS) maintains smaller data structures for a thread than for a process. In relation to this, which of the following is TRUE?",
    "choice1": "On per-thread basis, the OS maintains only CPU register state",
    "choice2": "The OS does not maintain a separate stack for each thread",
    "choice3": "On per-thread basis, the OS does not maintain virtual memory state",
    "choice4": "On per-thread basis, the OS maintains only scheduling and accounting information.",
    "answer": 3,
    "explanation": "Correct answer is (C). Threads share the address space of the process, so the operating system does not maintain separate virtual memory state for each thread."
  },
  {
    "question": "Let the page fault service time be 10ms in a computer with an average memory access time being 20ns. If one page fault is generated for every 10^6 memory accesses, what is the effective access time for the memory?",
    "choice1": "21ns",
    "choice2": "30ns",
    "choice3": "23ns",
    "choice4": "35ns",
    "answer": 2,
    "explanation": "Correct answer is (B). Effective memory access time is calculated considering both page faults and normal memory access time."
  },
  {
    "question": "An application loads 100 libraries at startup. Loading each library requires exactly one disk access. The seek time of the disk to a random location is given as 10ms. Rotational speed of the disk is 6000rpm. If all 100 libraries are loaded from random locations on the disk, how long does it take to load all libraries? (The time to transfer data from the disk block once the head has been positioned at the start of the block may be neglected)",
    "choice1": "0.50s",
    "choice2": "1.50s",
    "choice3": "1.25s",
    "choice4": "1.00s",
    "answer": 2,
    "explanation": "Correct answer is (B). The total time to load all libraries includes the average seek time and rotational latency for each library."
  },
  {
    "question": "Consider the following table of arrival time and burst time for three processes P0, P1, and P2. The pre-emptive shortest job first scheduling algorithm is used. Scheduling is carried out only at the arrival or completion of processes. What is the average waiting time for the three processes?\n\n| Process | Arrival time | Burst Time |\n|---------|--------------|------------|\n| P0      | 0 ms         | 9 ms       |\n| P1      | 1 ms         | 4 ms       |\n| P2      | 2 ms         | 9 ms       |",
    "choice1": "5.0 ms",
    "choice2": "4.33 ms",
    "choice3": "6.33 ms",
    "choice4": "7.33 ms",
    "answer": 1,
    "explanation": "Correct answer is (A). With the pre-emptive shortest job first scheduling algorithm, processes are scheduled based on their burst times. The average waiting time is calculated based on the waiting time of each process."
  }
]
